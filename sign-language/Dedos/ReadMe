Sign Language Recognition System

This project implements a real-time sign language recognition system using YOLOv8, OAK-D camera, Tkinter interfaces, and MQTT communication.
It combines computer vision, machine learning, and IoT to interpret hand gestures and translate them into structured commands for smart environments (e.g., home automation).

ğŸš€ Features

YOLOv8-based gesture recognition (custom-trained models).

Graphical interfaces with Tkinter for real-time visualization.

Data collection pipeline with OAK-D camera and threaded saving.

Buffer-based filtering to reduce false positives.

Command parsing pipeline: Activation â†’ Action â†’ Location/Time.

MQTT integration for IoT device communication.

Real-time timer control (minutes/seconds).

ğŸ“‚ Project Structure
.
â”œâ”€â”€ yolo_interface.py          # Tkinter GUI with YOLO hand detection
â”œâ”€â”€ image_capture.py           # Capture images from OAK-D for dataset
â”œâ”€â”€ phrase_display.py          # Tkinter GUI to display final phrase with timer
â”œâ”€â”€ full_pipeline.py           # Main project: YOLO + MQTT + Timers
â”œâ”€â”€ models/                    # Trained YOLOv8 models (Activation, Actions, Place, Time)
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ README.md                  # Project documentation

ğŸ› ï¸ Requirements

Python 3.9+

OpenCV

Tkinter

Pillow

DepthAI SDK

Ultralytics YOLOv8

Paho MQTT

Install all dependencies:

pip install -r requirements.txt


Example requirements.txt:

ultralytics
opencv-python
pillow
depthai
paho-mqtt

ğŸ“– Modules
1. yolo_interface.py â€“ YOLO Tkinter GUI

Loads a YOLO model (best.pt).

Opens webcam feed.

Displays:

Number of detected fingers

Classes detected

Confidence and area stats

Provides start/stop detection buttons.

2. image_capture.py â€“ Dataset Collection

Uses OAK-D camera via DepthAI.

Captures labeled images for each gesture (labels list).

Saves images in organized folders with UUID names.

Runs threaded saving for efficiency.

3. phrase_display.py â€“ GUI for Final Phrase

Tkinter window showing:

Final recognized phrase

Topic and message (for MQTT context)

Countdown timer (MM:SS).

Timer runs in a separate thread with queue communication.

4. full_pipeline.py â€“ Full System with MQTT

Loads four YOLO models:

Activacion.pt (activation gestures, e.g. AtenciÃ³n)

Acciones.pt (actions, e.g. Abrir, Cerrar, LuzOn, LuzOff)

Lugar.pt (places, e.g. Cocina, Sala, Casa)

Tiempo.pt (time, e.g. 1, 2, 5, 10).

Uses buffers to filter noisy predictions.

Flow:

Detect "AtenciÃ³n" â†’ Switch to actions model.

Detect an action â†’ Switch to location or time model.

Detect place/time â†’ Build final phrase.

Send via MQTT.

Supports timeouts to reset on inactivity.

MQTT publishes to Casa and specific topics (e.g. Cocina).

Timer integration with MQTT publishing when countdown ends.

âš¡ Usage

Clone repo & install dependencies.

Place trained YOLO models (*.pt) inside models/.

Run modules as needed:

Run YOLO GUI:

python yolo_interface.py


Capture dataset images:

python image_capture.py


Display final phrase with timer:

python phrase_display.py


Run full system with MQTT:

python full_pipeline.py

ğŸ”— Example Workflow

User performs sign â†’ "AtenciÃ³n".

Action model detects â†’ "Abrir".

Place model detects â†’ "Cocina".

Final phrase: "AtenciÃ³n Abrir Cocina".

System publishes MQTT message:

Topic: Cocina
Message: Abrir

ğŸ“Œ Notes

The YOLO .pt models are not included in this repository. Train your own or request access.

Recommended hardware: OAK-D Lite camera.

MQTT broker defaults to broker.emqx.io:8883 (can be configured).
